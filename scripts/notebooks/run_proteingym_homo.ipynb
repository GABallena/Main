{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring ProteinGym Data with Prime (Homo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def read_seq(seq_file):\n",
    "    for record in SeqIO.parse(seq_file, \"fasta\"):\n",
    "        return str(record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"AI4Protein/Prime_690M_HomoTune\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def score(fasta, mutant):\n",
    "    df = pd.read_csv(mutant)\n",
    "    sequence = read_seq(fasta)\n",
    "    tokenied_results = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    input_ids = tokenied_results.input_ids.to(device)\n",
    "    attention_mask = tokenied_results.attention_mask.to(device)\n",
    "    logits = model(input_ids, attention_mask=attention_mask).logits[0, 1:-1, :].log_softmax(dim=-1)\n",
    "    scores = []\n",
    "    for mutant in df[\"mutant\"]:\n",
    "        score = 0\n",
    "        for sub_mutant in mutant.split(\":\"):\n",
    "            wt, idx, mt = sub_mutant[0], int(sub_mutant[1:-1]) - 1, sub_mutant[-1]\n",
    "            score += (logits[idx, tokenizer.get_vocab()[mt]] - logits[idx, tokenizer.get_vocab()[wt]]).item()\n",
    "        scores.append(score)\n",
    "    df[\"predict_score\"] = scores\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_folder = Path(\"../proteingym_v1.0_fasta/fasta\")\n",
    "mutant_folder = Path(\"../proteingym_v1.0_fasta/mutant\")\n",
    "output_folder = Path(\"../proteingym_v1.0_fasta/scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sequence_folder.glob(\"*.fasta\"):\n",
    "    stem = file.stem\n",
    "    df = score(file, mutant_folder / f\"{stem}.csv\")\n",
    "    df.to_csv(output_folder / f\"{stem}.csv\", index=False)\n",
    "    print(f\"Scoring {stem}, rs = {spearmanr(df['score'], df['predict_score']).correlation:.4f}, saved to {output_folder / f'{stem}.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
